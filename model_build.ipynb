{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seed_torch(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, hidden_size, heads=3, dropout=0.2):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        assert hidden_size % heads == 0\n",
    "        self.query = nn.Linear(hidden_size, hidden_size)\n",
    "        self.key = nn.Linear(hidden_size, hidden_size)\n",
    "        self.value = nn.Linear(hidden_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.heads = heads\n",
    "        self.attn_size = int(hidden_size / heads)\n",
    "    \n",
    "    def transpose_for_scores(self, x, layer):\n",
    "        x = layer(x)\n",
    "        new_shape = x.size()[:-1] + (self.heads, self.attn_size)\n",
    "        x = x.view(*new_shape).permute(0, 2, 1, 3)\n",
    "        return x\n",
    "        \n",
    "    def forward(self, hidden_stations, attention_mask):\n",
    "        attention_mask = attention_mask.mask_fill_(attention_mask, -1e9)\n",
    "        # (batch_size, seq_len, hidden_size)\n",
    "        hidden_shape = hidden_stations.size()\n",
    "        # query: (batch_size, heads, seq_len, attn_size)\n",
    "        query = self.transpose_for_scores(hidden_stations, self.query)\n",
    "        key = self.transpose_for_scores(hidden_stations, self.key)\n",
    "        value = self.transpose_for_scores(hidden_stations, self.value)\n",
    "        \n",
    "        # (batch_size, heads, query_len, key_len)\n",
    "        attention_weight = torch.matmul(query, key.transpose(-1,-2)) / math.sqrt(self.attn_size)\n",
    "        attention_weight = attention_weight + attention_mask\n",
    "        attention_weight = nn.Softmax(dim=-1)(attention_weight)\n",
    "        \n",
    "        attention_weith = self.dropout(attention_weight)\n",
    "        \n",
    "        # (batch_size, heads, query_len, attn_size)\n",
    "        context = torch.matmul(attention_weight, value)\n",
    "        context = context.permute(0,2,1,3).contiguous()\n",
    "        context = context.view(*hidden_shape)\n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNNLayer(nn.Module):\n",
    "    def __init__(self, hidden_size, filters, seq_len, dropout=0):\n",
    "        super(CNNLayer, self).__init__()\n",
    "        self.layer_1 = nn.Conv2d(1, filters, kernel_size=(1, hidden_size))\n",
    "        self.layer_2 = nn.Conv2d(filters, filters, kernal_size=(seq_len, 1))\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(seq_len, 1))\n",
    "        self.dense = nn.Linear(2*filters, 1)\n",
    "        # self.dropout = nn.Dropout(dropout)\n",
    "        self.filters = filters\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # (batch_size, 1, seq_len, hidden_size)\n",
    "        x = x.unsqueeze(1)\n",
    "        # (batch_size, filters, seq_len, 1)\n",
    "        conv1 = F.relu(self.layer_1(x))\n",
    "        # (batch_size, filters, 1, 1)\n",
    "        out1 = F.relu(self.layer_2(conv1)).squeeze(2).squeeze(3)\n",
    "        out2 = self.maxpool(conv1).squeeze(2).squeeze(3)\n",
    "        out = torch.cat([out1, out2], dim=1)\n",
    "        out = self.dense(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MixModel(nn.Module):\n",
    "    def __init__(self, attn_layer, cnn_layer, pre_train_embedding, freeze=False):\n",
    "        super(MixModel, self).__init__()\n",
    "        self.attn_layer = attn_layer\n",
    "        self.cnn_layer = cnn_layer\n",
    "        self.embed_layer = nn.Embedding.from_pretrained(pre_train_embedding, freeze=freeze)\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if name.find('embed') > -1:\n",
    "                continue\n",
    "            elif name.find('weight') > -1 and len(param.size()) > 1:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        embed = self.embed_layer(x)\n",
    "        # (batch, seq_len, hidden_size)\n",
    "        attn = self.attn_layer(embed, mask)\n",
    "        cnn_mask = mask[:,0,:].squeeze(1).unsqueeze(2)\n",
    "        cnn_mask = cnn_mask == 0\n",
    "        cnn_input = attn * cnn_mask\n",
    "        out = self.cnn_layer(cnn_input)\n",
    "        return out\n",
    "    \n",
    "    def predict(self, dataloader):\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                batch = tuple(t.to(device) for t in batch)\n",
    "                X_batch, = batch\n",
    "                preds.append(self.forward(X_batch).data.cpu())\n",
    "        return torch.cat(preds)\n",
    "\n",
    "    def predict_proba(self, dataloader):\n",
    "        return torch.sigmoid(self.predict(dataloader)).data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_epoch(model, dataloader, optimizer, callbacks=None,\n",
    "              criterion=nn.BCEWithLogitsLoss(), verbose_step=10000):\n",
    "    t1 = time.time()\n",
    "    tr_loss = 0\n",
    "    for step, batch in enumerate(dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        x_batch, y_batch = batch\n",
    "        model.zero_grad()\n",
    "        outputs = model(x_batch)\n",
    "        loss = criterion(outputs[:, 0], y_batch.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tr_loss += loss.item()\n",
    "        if callbacks is not None:\n",
    "            for func in callbacks:\n",
    "                func.on_batch_end(model)\n",
    "        if (step + 1) % verbose_step == 0:\n",
    "            loss_now = tr_loss / (step + 1)\n",
    "            print(f'step:{step+1} loss:{loss_now:.7f} time:{time.time() - t1:.1f}s')\n",
    "    if callbacks is not None:\n",
    "        for func in callbacks:\n",
    "            func.on_epoch_end(model)\n",
    "    return tr_loss / (step + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_build(embedding_matrix, head=6, max_seq_len=50, cnn_filter=128):\n",
    "    embedding_size = len(embedding_matrix[0])\n",
    "    atten_layer = SelfAttention(hidden_size=embedding_size, heads=heads, dropout=0.2)\n",
    "    cnn_layer = CNNLayer(hidden_size=embedding_size, filters=128, seq_len=max_seq_len)\n",
    "    model = MixModel(attn_layer, cnn_layer, pre_train_embedding=embedding_matrix,freeze=False)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1000000000.0"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = SelfAttention(6, heads=1, dropout=0)\n",
    "for name, p in layer.named_parameters():\n",
    "    p.data = torch.ones(p.size()) * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "context, = layer(x, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.3301, 0.3425, 0.3274, 0.0000],\n",
       "          [0.2857, 0.4566, 0.2577, 0.0000],\n",
       "          [0.3382, 0.3192, 0.3426, 0.0000],\n",
       "          [0.2698, 0.4939, 0.2363, 0.0000]]]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1495, 0.1495, 0.1495, 0.1495, 0.1495, 0.1495],\n",
       "         [0.2039, 0.2039, 0.2039, 0.2039, 0.2039, 0.2039],\n",
       "         [0.1383, 0.1383, 0.1383, 0.1383, 0.1383, 0.1383],\n",
       "         [0.2215, 0.2215, 0.2215, 0.2215, 0.2215, 0.2215]]],\n",
       "       grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1495, 0.1495, 0.1495, 0.1495, 0.1495, 0.1495],\n",
       "         [0.2039, 0.2039, 0.2039, 0.2039, 0.2039, 0.2039],\n",
       "         [0.1383, 0.1383, 0.1383, 0.1383, 0.1383, 0.1383],\n",
       "         [0.2215, 0.2215, 0.2215, 0.2215, 0.2215, 0.2215]]],\n",
       "       grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
